---
title: How I got into the Hall of Fame
header-includes:
  - \usepackage{xcolor}
  - \usepackage{lipsum}
  - \setlength{\parskip}{0.25em}
  - \pagenumbering{arabic}
affiliation:
  ## use one only of the following
  # author-columnar: true         ## one column per author
  #institution-columnar: true  ## one column per institution (multiple autors eventually)
  wide: true                  ## one column wide author/affiliation fields

  institution:
    - name: Universitat Polit√®cnica de Catalunya
      department: Computer Science
      location: C/ Jordi Girona 1, Barcelona
      mark: 1
      author:
        - name: Unai Perez Mendizabal
          email: unai.perez.mendizabal@est.fib.upc.edu
        - name: Damian Rubio Cuervo
          email: damian.rubio.cuervo@est.fib.upc.edu
abstract: |
  The abstract goes here.
  On multiple lines eventually.

#bibliography: mybibfile.bib
output: rticles::ieee_article
---

```{r include=F}
library(DMwR)
library(chemometrics)
library(FactoMineR)
library(fpc)
library(caret)
library(RColorBrewer)
library(ROCR)
library(ROSE)
library(rpart.plot)
library(kableExtra)

baseball.dataset <- read.csv("../baseball.csv", na.strings = c('?'),
    colClasses = c("character", rep("integer", 11), rep("double", 4), rep("factor", 2)))
```

#Introduction

This paper aims to study the *Hall of Fame* dataset. It comprises a list of different american baseball players, including a collection of statistics about each one of them, corresponding to their whole careers. The Hall of Fame refers to an official recognition that a few organizations may (or may not) give to certain players with outstanding careers. The *Veterans Committee* (VC for short) and the *BaseBall Writers Association of America* (BBWAA) are two of these organizations. The statistics included in the dataset are the following:

- **`Player`**: Character. Variable representing the name of the player. It will not be used during the analysis, but only to label the individuals.
- **`Number_seasons`**: Count data representing how namy seasons the player has played in the league.
- **`Games_played`**: Count data representing how many games the player has played.
- **`At_bats`**: Count data representing the number of times a player has been in the hitter position.
- **`Runs`**: Count data representing the number of runs a player has achieved.
- **`Hits`**: Count data representing the number of hits a player has achieved.
- **`Doubles`**: Count data representing the number of doubles a player has achieved. This happens when the player runs through two bases after one hit.
- **`Triples`**: Count data representing the number of triples a player has achieved. This happens when the player runs through three bases after one hit.
- **`Home_runs`**: Count data representing the number of home runs a player has achieved.
- **`RBIs`**: Count data representing the number of runs-batted-in a player has achieved. That is the number of runs that were completed after one of the player's hit.
- **`Walks`**: Count data representing the number of walks a player has made. This happens when the pitcher throws the ball poorly four times and the batter is allowed to just walk to the first base.
- **`Strikeouts`**: Count data representing the number of times the player has been eliminated due to three strikes.
- **`Batting_average`**: Countinuous numerical data representing the average number of hits a player made when in the hitter position. 
- **`On_base_pct`**: Continuous data representing how frequently a batter reaches the base taking into account the times he has been in the batter position.
- **`Slugging_pct`**: Continuous data representing a measure of the batting productivity of a player. It is calculated with the formula below, where `1B` to `4B` refer to all possible outcomes of a hit (from single to home run) and `AB` refers to `At-Bats`. $$SLG = \frac{(1B) + (2 \times 2B) + (3 \times 3B) + (4 \times 4B)}{AB}$$
- **`Fielding_ave`**: Continuous data representing the average times a defensive player properly handles a batted or thrown ball.
- **`Position`**: Factor. Variable that represents the position of the player in the field. The possible values are catcher, designated hitter, first base, outfield (That encloses the positions of Right field, Left Field and Center Field), second base, short stop and third base. These are all defensive positions, except for the designated hitter.
- **`Hall_of_Fame`**: Categorical variable. This is the target variable. Originally, it has three categories that represent players not included in the hall of fame with 0, players included in the hall of fame by the Baseball Writers' Association of America (BBWAA) with 1, and players included in the hall of fame by the Veterans Committee (VC) with 2.

The dataset has `r nrow(baseball.dataset)` observations, from which, only `r length(which(baseball.dataset$Hall_of_Fame != 0))` are players that made it into the Hall of Fame.

# Data preprocessing

Values `1` and `2` of the class target `Hall_Of_Fame`, which is a factor, count as being in the Hall of Fame. The different values make a reference to the evaluation committee that accepted the players into the Hall. Depending on what procedure or analysis is run over the dataset, it might be useful to keep the different committees well labelled and differentiated. On the other hand, there are very few Hall of Fame players, so dividing them into two smaller categories seems unprofitable; the samples would get very small. The two categorizations have been kept for potential usage.

```{r include=FALSE, cache=F}
levels(baseball.dataset$Hall_of_Fame) <- c("no", "BBWAA", "VC")
```

As for the individuals, the name `ELMER_SMITH` is duplicated. A quick search in Wikipedia tells that there are two former players by the name of Elmer Smith. The data matches: One had played 10 seasons and the other 14, so it is not mislabelled data, and removing it would mean data loss. According to Wikipedia, the one that played 14 seasons is however more generally known as Mike Smith. So its name was replaced to `MIKE_SMITH`, which does not match any other player in the set. Also, the players' names are originally considered as one variable. They are going to be used as the row names and the variable is going to be removed.

```{r include=FALSE, cache=F}
baseball.dataset[baseball.dataset$Player == "ELMER_SMITH" & baseball.dataset$Number_seasons == 14, "Player"] <- "MIKE_SMITH"

rownames(baseball.dataset) <- baseball.dataset$Player
baseball.dataset$Player <- NULL
```

## Missing data and imputation

Missing data in the dataset is represented as question marks (`?`). This happens to `r length(which(is.na(baseball.dataset$Strikeouts)))` observations in the `Strikeouts` variable. Only `r length(which(is.na(baseball.dataset$Strikeouts) & baseball.dataset$Hall_of_Fame != "no"))` out of the `r length(which(is.na(baseball.dataset$Strikeouts)))` is a Hall of Fame player. Actually, the hetereogeneity of the dataset, regarding the proportion of Hall of Fame and non Hall of Fame players, is pretty similar in the whole population and in the sample with missing values (`r round(nrow(baseball.dataset[baseball.dataset$Hall_of_Fame != "no",])/nrow(baseball.dataset), 3)` vs. `r nrow(baseball.dataset[baseball.dataset$Hall_of_Fame != "no" & is.na(baseball.dataset$Strikeouts),])/nrow(baseball.dataset[is.na(baseball.dataset$Strikeouts),])`). So, this sample has been considered relevant and has been imputed.

For this task, chained equations, PCA and kNN imputations have been tried. The chained equations method is not deterministic, but in most, if not all, of the attempts the imputed values decreased the mean of the variable significantly. PCA, on the contrary, increased the mean too much. kNN gave the results that most closely followed realistic values.

```{r include=F}
na.strikeouts <- which(is.na(baseball.dataset$Strikeouts))
baseball.dataset.knn <- knnImputation(baseball.dataset)
baseball.dataset.knn$Strikeouts <- round(baseball.dataset.knn$Strikeouts)
baseball.dataset$Strikeouts[na.strikeouts] <- baseball.dataset.knn$Strikeouts[na.strikeouts]
```

## Outliers

```{r include=FALSE}
all.outliers <- Moutlier(baseball.dataset[,1:15], plot=F)
no.hall.outliers <- Moutlier(baseball.dataset[baseball.dataset$Hall_of_Fame == "no",1:15], plot=F)
par(mfrow=c(1,1))
```

```{r echo=FALSE, fig.cap="\\label{fig:rmahalanobis-distance}Mahalanobis distances with and without Hall of Fame", fig.pos="!b", out.extra=''}
par(mfrow=c(1,2))
plot(x=1:length(all.outliers$rd), y=all.outliers$rd, pch=19, cex=0.7, axes=F, xlab="", ylab="", col=as.character(lapply(baseball.dataset$Hall_of_Fame, function(x) ifelse(x == "no", "dodgerblue", "firebrick1"))))
abline(h=all.outliers$cutoff, lty=2, lwd=3)
axis(2, at=seq(from = 0, to = ceiling(max(all.outliers$rd)), by=(ceiling(max(all.outliers$rd))/5)), cex.axis=.7)
axis(1, cex.axis=.6)
no.hall.outlier.names <- rownames(baseball.dataset[baseball.dataset$Hall_of_Fame == "no",][order(no.hall.outliers$rd, decreasing = T)[1:round(nrow(baseball.dataset) * 0.025)],])
plot(no.hall.outliers$rd, pch=20, axes=F, col=as.character(lapply(rownames(baseball.dataset[baseball.dataset$Hall_of_Fame == "no",]), function(x) ifelse(x %in% no.hall.outlier.names, "firebrick1", "dodgerblue"))), xlab="", ylab="", cex=.7)
axis(2, at=seq(from = 0, to = ceiling(max(no.hall.outliers$rd)), by=ceiling(max(no.hall.outliers$rd)/5)), cex.axis=.7)
axis(1, cex.axis=.6)
par(mfrow=c(1,1))
```

Looking at the summary of the dataset, it seems like some variables have suspicious maximum and minimum values. For example, variable `RBIs` has a minimum value of 21. This value is far away from the mean of the variable and far below its first quartile. It can be seen in the boxplots of figure \ref{fig:rbi-univariate} that the range of the `RBIs` variable changes drastically when including or omitting the hall of fame players. The minimum value of `RBIs` for the hall of fame players is much higher than the overall minimum. This means that the dataset's discordant maximum and minimum values may not really be representative of univariate outliers, becuase of the two really different populations that the dataset mixes. This will also be applied to the rest of continuous variables that show suspicious values, such as `Walks` or `Strikeouts`.

```{r echo=FALSE, fig.height=3, fig.cap="\\label{fig:rbi-univariate}Univariate outlier detection over RBIs variable", cache=F}
par(mfrow=c(1, 3))
boxplot(baseball.dataset$RBIs, outcol="firebrick1", main="All players")
boxplot(baseball.dataset[baseball.dataset$Hall_of_Fame != "no", "RBIs"], outcol="firebrick1", main="Hall of fame")
boxplot(baseball.dataset[baseball.dataset$Hall_of_Fame == "no", "RBIs"], outcol="firebrick1", main="Not hall of fame")
par(mfrow=c(1, 1))
```

But, as for the averaging statistics, a different criteria should be applied. Specifically, the `Fielding_ave` variable has a maximum value of exactly `1`. Only one player, labelled as `r row.names(baseball.dataset)[which.max(baseball.dataset$Fielding_ave)]`, has the given value. This would mean that every time the player defended, the opposing team scored no runs. Still, the player did not make it into the Hall of Fame. However, the mean of the variable is pretty high (`r mean(baseball.dataset$Fielding_ave)`). Without any more knowledge, this will not be considered an outlier.

As for multivariate outliers, the robustified Mahalanobis distance has been used for their detection. The plots of figure \ref{fig:rmahalanobis-distance} represent the distances of the individuals. The plot on the left shows in red those players that made it into the Hall of Fame, and in blue the ones that did not. It is obvious that the plot considers most of the players in the hall of fame as outliers, and there is a reason for that: They were considered for the hall of fame for their outstanding stats and performances indeed. These players kind of behave like outliers in real life, but that is the point. So, they will not be treated as outliers.

The plot on the right of the figure \ref{fig:rmahalanobis-distance} shows only players that are not in the hall of fame. It can be seen that some players still exceed other players. These could actually be considered outliers. If we consider to discard the 2.5% of the individuals, this is, the `r ceiling(nrow(baseball.dataset) * 0.025)` with the greatest robustified Mahalanobis distance for being outliers, then those individuals plotted in red will be discarded. The player that most outlies from those excluded from the hall of fame actually has stats that are outstanding, so one can not help but wonder why he was not included. This player is Pete Rose and, as noted by [`Wikipedia`](https://en.wikipedia.org/wiki/Pete_Rose), he has been involved in tax evasion and gambling controversy, which probably affected the commitees' decision making.

```{r include=FALSE, cache=F}
baseball.dataset <- baseball.dataset[-which(rownames(baseball.dataset) %in% no.hall.outlier.names),]
```

```{r echo=F, fig.cap="\\label{fig:season-barplot}Stacked barplot for played seasons", fig.pos="!t", out.extra=''}
baseball.dataset.binary <- data.frame(baseball.dataset)
levels(baseball.dataset.binary$Hall_of_Fame) <- c("no", "yes", "yes")
barplot(table(baseball.dataset.binary$Hall_of_Fame, cut(baseball.dataset.binary$Number_seasons, breaks = seq(min(baseball.dataset.binary$Number_seasons), max(baseball.dataset.binary$Number_seasons), length.out = 5))), col=rev(brewer.pal(4, "Purples"))[1:2])
legend("topright", legend=c("Hall of Fame", "Not Hall of Fame"), fill=rev(rev(brewer.pal(4, "Purples"))[1:2]))
```

# Data exploration

Via visual data exploration, we might be able to obtain some useful information about the criteria of admission into the Hall of Fame. For example, one can reasonably think that the players that have the longest careers should be good enough or, at least, some kind of recognisable figure that is worth the acceptance into the Hall of Fame. Nevertheless, as barplot in figure \ref{fig:season-barplot} shows, there is no strong correlation between the season amount and the Hall of Fame. As careers grow longer, players that keep playing do end up getting accepted, but the amount of players accepted per each bar does not vary too much.

```{r include=F, warning=F}
chisq <- chisq.test(baseball.dataset[,c("Number_seasons", "Games_played")])
```

Variable `Games_played` should be strongly correlated with `Number_seasons`, meaning the variables are statistically dependent. Running a $\chi^2$ test with the two variables gives a p-value of `r round(chisq$p.value, 3)`, which allows us to reject the null hypothesis $H_0$ that states that the variables are independent. And thus, the barplot on figure \ref{fig:games-played-barplot} does not show a but a slight increase in the number of Hall of Fame players. All variables are mostly related to `Number_seasons`, because the more seasons a player plays, the highest chance he has of scoring more in this statistics. Actually, the $\chi^2$ p-value for the whole dataset is `r round(chisq.test(baseball.dataset[,1:15])$p.value, 6)`, so no independece can be taken for granted.

Oddly enough, baseball is a mostly defensive sport. The defensive part of it is when players need a more strategic and collaborative response. And, still, most of the variables are related to the offensive part of baseball, and, therefore, they are closely tied to the amount of games and seasons. That is the case for all but the `Fielding_ave` variable, which refers to the amount of plays in which the player has taken part into the putout of another player. Barplot in figure \ref{fig:fielding-ave-barplot} shows the relation between the best recorded defenders and the players that got in the Hall of Fame. The better defenders they are, the highest is the chance to make it in. But also, the amount of discarded players increases as the number increases too. This leads to the conclusion that being a good defender is important to be a good player, and also that players that are just good defenders are not taken all that much into account.

```{r echo=F, fig.cap="\\label{fig:games-played-barplot}Stacked barplot of played games", fig.pos="!t", out.extra=''}
range.games.played <- cut(baseball.dataset.binary$Games_played, breaks = seq(min(baseball.dataset.binary$Games_played), max(baseball.dataset.binary$Games_played), length.out = 10), dig.lab = 5)
games.played.barplot <- barplot(table(baseball.dataset.binary$Hall_of_Fame, range.games.played), col=rev(brewer.pal(4, "Blues"))[1:2], xaxt="n")
text(x = games.played.barplot + .5, y = -13, labels=levels(range.games.played), xpd=T, srt=30, pos=2)
text(x = games.played.barplot, y = margin.table(table(baseball.dataset.binary$Hall_of_Fame, range.games.played), 2) + 10, labels=table(baseball.dataset.binary$Hall_of_Fame, range.games.played)[2,], xpd=T)
legend("topright", legend=c("Hall of Fame", "Not Hall of Fame"), fill=rev(rev(brewer.pal(4, "Blues"))[1:2]))
```

```{r echo=F, fig.cap="\\label{fig:fielding-ave-barplot}Stacked barplot of fielding average", fig.pos="!b", out.extra=''}
fielding.ave.range <- cut(baseball.dataset.binary$Fielding_ave, breaks = seq(min(baseball.dataset.binary$Fielding_ave), max(baseball.dataset.binary$Fielding_ave), length.out = 10))
fielding.barplot <- barplot(table(baseball.dataset.binary$Hall_of_Fame, fielding.ave.range), xaxt='n', col=rev(brewer.pal(3, "Greens"))[1:2])
text(x = fielding.barplot + .5, y = -20, labels=levels(fielding.ave.range), xpd=T, srt=30, pos=2)
legend("topleft", legend=c("Not Hall of Fame", "Hall of Fame"), fill=rev(rev(brewer.pal(3, "Greens"))[1:2]))
```

A player needs to stand out in as much statistics as possible to make into the Hall of Fame. In the end, as the plot in figure \ref{fig:rmahalanobis-distance} makes the most clear statement regarding what it really takes to be considered a great player: You need to be an outlier and, indeed, stand out in all the possible ways. Let's take a deeper look into all of this with some analysis.

# Logistic regression

Being the target variable categorical, the most appropriate way to perform a regression is through logistic regression. The output of this regression follows a Bernoulli distribution and permits the transformation into the categories of the variable. To do so, the version of the dataset with binary target variable has been used.

The variables of the data are heterogeneous. Variable `Number_seasons` is an integer that ranges from `r min(baseball.dataset$Number_seasons)` to `r max(baseball.dataset$Number_seasons)`, and `Hits`, while also being an integer, ranges from `r min(baseball.dataset$Hits)` to `r max(baseball.dataset$Hits)`. Also, four of the variables are percentages (with decimals) going from 0 to 1. The variables need to be standardized so that they can be used together without causing distortion in the results.

```{r include=F, cache=T}
N <- nrow(baseball.dataset.binary)
N.training <- ceiling(2 * N / 3)
N.test <- N - N.training
training.sample.indices <- sample(1:N, size = N.training)
training.sample <- baseball.dataset.binary[training.sample.indices,]
test.sample <- baseball.dataset.binary[-training.sample.indices,]

train.control <- trainControl(method = "cv", number=10, sampling="up")
model <- train(Hall_of_Fame ~ ., data = training.sample[,-16], preProcess = c("scale", "center"), method="glm", family=binomial(link="logit"), trControl=train.control)
```

```{r echo=F, fig.cap="\\label{fig:roc-table-log-regression}ROC table of the best logistic regression model", cache=T, out.extra=""}
predicted.values <- predict(model$finalModel, newdata = test.sample)
roc.pred <- prediction(predicted.values, test.sample$Hall_of_Fame)
roc.perf <- performance(roc.pred, "tpr", "fpr")
plot(roc.perf, colorized=T)
```

For the selection of the best possible model, the dataset has been split into a training and a test sets, each being two thirds and one third of the whole dataset, and a 10-fold cross validation process has been applied for the training. Due to the big disproportion between the Hall of Fame players and the no Hall of Fame players, it could be reasonable to think that the model could end up working with unbalanced samples and, therefore, underfit or biased. Actually, the random samples for the validation are pretty equally split. On the other hand, it could be easier to end up with unbalanced samples in the cross validation step. To avoid this, the Hall of Fame players have been oversampled. The best found model has an accuracy of `r round(model$results$Accuracy, 3)`, which is not great but is still really good. The ROC curve for the model is shown in figure \ref{fig:roc-table-log-regression}. The Area Under the Curve (AUC) is `r round(as.numeric(performance(roc.pred, measure="auc")@y.values), 3)`.

# Clustering

In order to see what variables of the dataset characterize more the individuals we are going to perform some component analysis. This will also allow us to perform some clustering techniques with just the part of the information that is more relevant for our analysis. The analysis we are going to do is called PCA. When doing such an analysis we can see how the different variables are respresented and how much of the information is given by each of the analysis. In figure \ref{fig:pca-analysis} we can see how the variables of the dataset correlate with the relevant dimensions. As we can see, the variables best represented in the first dimension are `RBIs` and `Games_played`, while only `Fielding_ave` seems to correlate with the second dimension.

As we want to reduce the dimensionality of the data to be able to visualize and analyze it in a better way, we will have to decide how many dimensions are relvant to us. For that purpose we will use all that dimensions that will allow us to guarantee that we are preserving at least 80% of the information on the sample. In this case, that threshold is reached with just the three first dimensions. From now on, an in order to perform the clustering we will use the coordinates of the individuals in just those three dimensions.

```{r include=F}
baseball.dataset.pca <- data.frame(baseball.dataset)
baseball.dataset.pca[,1:15] <- scale(baseball.dataset.pca[,1:15])
pca.results <- PCA(baseball.dataset, quali.sup = 16:17, graph = F)
```

```{r echo=FALSE, fig.cap="\\label{fig:pca-analysis}PCA Analysis of the Hall Of Fame.", fig.pos="!t"}
plot.PCA(pca.results, choix=c("varcor"))
```

```{r include=F}
baseball.data.matrix <- pca.results$ind$coord[,1:3]
baseball.distance.matrix <- dist(baseball.data.matrix, upper = TRUE, diag = TRUE)
baseball.hclust <- hclust(d = baseball.distance.matrix, method = 'ward.D2')
baseball.hclust.clusters <- cutree(baseball.hclust, k = 2)

# Comparing yes/no hall of fame results with the clusters
baseball.clustered <- cbind(baseball.dataset, baseball.hclust.clusters)
colnames(baseball.clustered) <- c(colnames(baseball.dataset), "Cluster")

# Players in cluster n1: 347
n1_total <- nrow(baseball.clustered[baseball.clustered$Cluster == 1,])
# Players in cluster n1 and Hall of fame: 116
n1_yes <- nrow(baseball.clustered[baseball.clustered$Cluster == 1 & baseball.clustered$Hall_of_Fame != 'no',])
# Players in cluster n2: 959
n2_total <- nrow(baseball.clustered[baseball.clustered$Cluster == 2,])
# Players in cluster n2 and Hall of fame: 9
n2_yes <- nrow(baseball.clustered[baseball.clustered$Cluster == 2 & baseball.clustered$Hall_of_Fame != 'no',])
```

The approach to clustering will be based on performing first a Hierarchical Clustering cutting it with the a priori knowledge we have, that is that there are only to clusters, one formed by players that entered the whole of fame and other with the ones that did not. In order to perform the clustering we will use the Ward distance metric. The results of this clustering are not trully representative of the classes that we know that exist in the data. If we cut the tree so that it gives us two clusters we will have `r n1_total` and `r n2_total` individuals in each cluster. The hall of fame players are divided as `r n1_yes` in the first cluster and `r n2_yes` in the second cluster. This tells us that `r round(n1_yes/(n1_yes+n2_yes)*100, 2)`% of them have been classified as been in the first cluster, but there they only represent `r round(n1_yes/n1_total*100, 2)`% of the total of individuals.

```{r include=F}
# Create a function to calculate the Calinski-Harabassz index
calinski_index = function(coordinates, hierarchical, n_clusters, consolidation) {
  # Get the clusters
  clusters = cutree(hierarchical, n_clusters)
  # Create a dataframe with the coordinates + the cluster
  df = data.frame(coordinates, Cluster = as.factor(clusters))
  if (consolidation == FALSE) { # if it is previous to consolidation step
    # Calculate the Calinski-Harabassz index
    index_value = calinhara(coordinates, df$Cluster, cn = max(clusters))
  }
  if (consolidation == TRUE) { # if it is posterior to consolidation step
    # Calculate the centroids with hierarchical
    centroids = aggregate(coordinates, list(df$Cluster), mean)
    # k-means taking as seeds the centroids calculated with hierarchical
    k_means = kmeans(coordinates, centers = centroids[,-1])
    # Create a dataframe with the coordinates + the k-means cluster
    df2 = data.frame(coordinates, Cluster = as.factor(k_means$cluster))
    # Calculate the Calinski-Harabassz index
    index_value = calinhara(coordinates, df2$Cluster, cn = max(k_means$cluster))
  }
  return(index_value)
}

# Create a vector with the Calinski index PRE consolidation for different values of k
baseball.calinski.hclust = calinski_index(pca.results$ind$coord[,1:3], baseball.hclust, 2, consolidation = FALSE)
for (i in 3:10){
  baseball.calinski.hclust = append(baseball.calinski.hclust, calinski_index(pca.results$ind$coord[,1:3], baseball.hclust, i, consolidation = FALSE))
}

# Create a vector with the Calinski index POST consolidation for different values of k
baseball.calinski.kmeans = calinski_index(pca.results$ind$coord[,1:3], baseball.hclust, 2, consolidation = TRUE)
for (i in 3:10){
  baseball.calinski.kmeans = append(baseball.calinski.kmeans, calinski_index(pca.results$ind$coord[,1:3], baseball.hclust, i, consolidation = TRUE))
}
```

```{r echo=FALSE, fig.cap="\\label{fig:calinski-harabassz}Clustering Evaluation by CH Index.", fig.pos="!b", out.extra=""}
# Plot the values of Calinski index
plot(baseball.calinski.kmeans, type = "o", xlab = 'Number of clusters', ylim=c(500,1300), ylab = 'Calinski value', main = 'Calinski-Harabassz Index', col = 'blue', xaxt = "n")
lines(baseball.calinski.hclust, type = "o", col = 'red', xaxt = "n")
axis(1, at=1:9, labels = c(2, 3, 4, 5, 6, 7, 8, 9, 10))
legend(5.5, 1320, legend=c("Index Before Consolodiation", "Index After Consolodiation"),
       col=c("red", "blue"), lty=c(1,1), cex=0.8)
```

In order to improve these results we are going to perform a consoloditaion step. This step will consist of a k-means clustering procedure that will start from the centroids of the clusters found in the hierarchical clustering and then iterationg until the optimal local solution is found. With the purpose of assesing to this step a metric that tells us if it improves the results we are going to use the Calinski-Harabassz index. This index has been run over both clusters, the hierarchical clustering without consolidation and the consolidated one. The results can be seen in figure \ref{fig:calinski-harabassz}. The greater the value of the index, the better the clustering has been. Thus, we should consider the consolidated clustering with just two clusters, the best result for this problem.

```{r include=F}
# Calculate the centroids with hierarchical
baseball.hclust.centroids = aggregate(baseball.data.matrix, list(baseball.hclust.clusters), mean)
baseball.cluster.consolidated = kmeans(baseball.data.matrix, centers = baseball.hclust.centroids[,-1])

# Comparing yes/no hall of fame results with the clusters
baseball.clustered <- cbind(baseball.dataset, baseball.cluster.consolidated$cluster)
colnames(baseball.clustered) <- c(colnames(baseball.dataset), "Cluster")

# Players in cluster n1: 347
n1_consolidated_total <- nrow(baseball.clustered[baseball.clustered$Cluster == 1,])
# Players in cluster n1 and Hall of fame: 116
n1_consolidated_yes <- nrow(baseball.clustered[baseball.clustered$Cluster == 1 & baseball.clustered$Hall_of_Fame != 'no',])
# Players in cluster n2: 959
n2_consolidated_total <- nrow(baseball.clustered[baseball.clustered$Cluster == 2,])
# Players in cluster n2 and Hall of fame: 9
n2_consolidated_yes <- nrow(baseball.clustered[baseball.clustered$Cluster == 2 & baseball.clustered$Hall_of_Fame != 'no',])
```

Now, the clustering provides us with the following results. The clusters split the baseball players so that cluster one contains `r n1_consolidated_total` and cluster two contains `r n2_consolidated_total` individuals. The hall of fame players are divided as `r n1_consolidated_yes` in the first cluster and `r n2_consolidated_yes` in the second cluster. This tells us that `r round(n1_consolidated_yes/(n1_consolidated_yes+n2_consolidated_yes)*100, 2)`% of the hall of fame players have been allocated into the first cluster, and that now they represent up to `r round(n1_consolidated_yes/n1_consolidated_total*100, 2)`% of the total of individuals in that cluster. These results prove to be much better than before. The distribution of the indivudals in the clusters over the first two dimensions found in the principal component analysis can be seen in figure \ref{fig:consolidated-clusters}.

```{r echo=FALSE, fig.cap="\\label{fig:consolidated-clusters}Clustering of Hall Of Fame.", fig.pos="!t"}
# Plot the clusters
plot(baseball.data.matrix[,1], baseball.data.matrix[,2],col=as.vector(baseball.clustered$Cluster), main = 'Consolidated Clustering', xlab = 'Dimension 1', ylab = 'Dimension 2')
legend("topleft", legend=c("Cluster 1", "Cluster 2"), pch=21, col=levels(as.factor(baseball.clustered$Cluster)))
```

# Classification

## Decision Trees

In order to be able to create a classifier that will be able to predict whether a baseball player with certain records enter the hall of fame or not we are going to build a decission tree. For that purpose we start by creating two subsets of the data that will be used to do holdout validation. As we have a really unbalanced dataset we've been oblied to perform oversampling regarding the players that enter the hall of fame, since the amount of them present in the sample is much lower than those that did not.

```{r include=F, cache=T}
baseball.dataset.binary <- data.frame(baseball.dataset)
levels(baseball.dataset.binary$Hall_of_Fame) <- c("no", "yes", "yes")

# Holdout sampling
N <- nrow(baseball.dataset.binary)
N.training <- ceiling(2 * N / 3)
N.test <- N - N.training
training.sample.indices <- sample(1:N, size = N.training)
training.sample <- baseball.dataset.binary[training.sample.indices,]
test.sample <- baseball.dataset.binary[-training.sample.indices,]

training.sample <- ROSE(Hall_of_Fame ~ ., data  = training.sample)$data

# TREE
baseball.tree <- rpart::rpart(Hall_of_Fame ~ ., data = training.sample, method = "class",
                              control = rpart.control(cp = 0.000001, xval = 10))
```

```{r echo=FALSE, fig.cap="\\label{fig:tree}Decission tree for hall of fame.", fig.pos="!t"}
rpart.plot(baseball.tree)
```

In first place we start by creating a pure decission tree. The shape of the tree can be seen in figure \ref{fig:tree} and its performance over the test sample are shown below.

```{r echo=FALSE, fig.cap="\\label{fig:tree-confusion}Decision's tree confusion matrix for hall of fame.", fig.align="center"}
tree.predicted <- predict(baseball.tree, test.sample,type="class")
confusion.matrix <- table(as.factor(test.sample[,"Hall_of_Fame"]), tree.predicted)
aux_confusion_matrix <- confusion.matrix
colnames(aux_confusion_matrix) <- c("Predicted No","Predicted Yes")
rownames(aux_confusion_matrix) <- c("True No","True Yes")

kable(aux_confusion_matrix)
```

With these values we can calculate some interesting statistics about pur classifier. The accuracy of the classifier, that is the proportion of instances that are properly classified is `r round((sum(diag(confusion.matrix))/sum(confusion.matrix))*100,2)`%. Even though this value is pretty high, it is not really representative for our example since we want to ensure that the maximum possible of players that enter the hall of fame are properly classified. Thus, we can measure the miss rate for that case, and we get it is `r round(confusion.matrix[2,1]/ (confusion.matrix[2,1] + confusion.matrix[2,2])*100,2)`%. It can be seen that a high volume of the interesting indivduals are been wrongly classified over the test sample. This can be due to overfittiong of the model. 

```{r include=F, cache=T}
baseball.cptable <- as.data.frame(baseball.tree$cptable)
minimum_error_index <- which.min(baseball.cptable$xerror)
minimum_xerror <- baseball.cptable[minimum_error_index, 'xerror']
minimum_xstd <- baseball.cptable[minimum_error_index, 'xstd']

optimal_index <- 1
while(baseball.cptable$xerror[optimal_index] > minimum_xerror + minimum_xstd)
  optimal_index <- optimal_index + 1

alpha <- baseball.cptable[optimal_index, 'CP']

# Do the cut
baseball.pruned.tree <- rpart::prune(baseball.tree, cp = alpha)
```

```{r echo=FALSE, fig.cap="\\label{fig:tree-pruned}Decission tree for hall of fame.", fig.pos="!t"}
rpart.plot(baseball.pruned.tree, extra = 101)
```

To solve this issue we are going to try to prune the tree. The shape of the tree can be seen in figure \ref{fig:tree-pruned} and its performance over the test sample are shown below. 

```{r echo=FALSE, fig.cap="\\label{fig:tree-confusion}Decision's tree confusion matrix for hall of fame.", fig.align="center"}
# Tree statistics
tree.predicted.pruned <- predict(baseball.pruned.tree, test.sample,type="class")
confusion.matrix.pruned <- table(as.factor(test.sample[,"Hall_of_Fame"]), tree.predicted.pruned)
aux_confusion_matrix <- confusion.matrix.pruned
colnames(aux_confusion_matrix) <- c("Predicted No","Predicted Yes")
rownames(aux_confusion_matrix) <- c("True No","True Yes")

kable(aux_confusion_matrix)
```


With these new values we observe that now the accuracy of the classifier is `r round((sum(diag(confusion.matrix.pruned))/sum(confusion.matrix.pruned))*100,2)`% and the new value for the miss rate for the case of a player being in the hall of fame is `r round(confusion.matrix.pruned[2,1]/ (confusion.matrix.pruned[2,1] + confusion.matrix.pruned[2,2])*100,2)`%. Now, when comparing these values with the previous ones, we can see that the proportion of players that entered the hall of fame and were predicted to do so has increased.

<!-- An example of a floating figure using the graphicx package. -->
<!-- Note that \label must occur AFTER (or within) \caption. -->``
<!-- For figures, \caption should occur after the \includegraphics. -->
<!-- Note that IEEEtran v1.7 and later has special internal code that -->
<!-- is designed to preserve the operation of \label within \caption -->
<!-- even when the captionsoff option is in effect. However, because -->
<!-- of issues like this, it may be the safest practice to put all your -->
<!-- \label just after \caption rather than within \caption{}. -->

<!-- Reminder: the "draftcls" or "draftclsnofoot", not "draft", class -->
<!-- option should be used if it is desired that the figures are to be -->
<!-- displayed while in draft mode. -->

<!-- \begin{figure}[!t] -->
<!-- \centering -->
<!-- \includegraphics[width=2.5in]{myfigure} -->
<!-- where an .eps filename suffix will be assumed under latex,  -->
<!-- and a .pdf suffix will be assumed for pdflatex; or what has been declared -->
<!-- via \DeclareGraphicsExtensions. -->
<!-- \caption{Simulation results for the network.} -->
<!-- \label{fig_sim} -->
<!-- \end{figure} -->

<!-- Note that the IEEE typically puts floats only at the top, even when this -->
<!-- results in a large percentage of a column being occupied by floats. -->


<!-- An example of a double column floating figure using two subfigures. -->
<!-- (The subfig.sty package must be loaded for this to work.) -->
<!-- The subfigure \label commands are set within each subfloat command, -->
<!-- and the \label for the overall figure must come after \caption. -->
<!-- \hfil is used as a separator to get equal spacing. -->
<!-- Watch out that the combined width of all the subfigures on a  -->
<!-- line do not exceed the text width or a line break will occur. -->

<!-- \begin{figure*}[!t] -->
<!-- \centering -->
<!-- \subfloat[Case I]{\includegraphics[width=2.5in]{box}% -->
<!-- \label{fig_first_case}} -->
<!-- \hfil -->
<!-- \subfloat[Case II]{\includegraphics[width=2.5in]{box}% -->
<!-- \label{fig_second_case}} -->
<!-- \caption{Simulation results for the network.} -->
<!-- \label{fig_sim} -->
<!-- \end{figure*} -->

<!-- Note that often IEEE papers with subfigures do not employ subfigure -->
<!-- captions (using the optional argument to \subfloat[]), but instead will -->
<!-- reference/describe all of them (a), (b), etc., within the main caption. -->
<!-- Be aware that for subfig.sty to generate the (a), (b), etc., subfigure -->
<!-- labels, the optional argument to \subfloat must be present. If a -->
<!-- subcaption is not desired, just leave its contents blank, -->
<!-- e.g., \subfloat[]. -->


<!-- An example of a floating table. Note that, for IEEE style tables, the -->
<!-- \caption command should come BEFORE the table and, given that table -->
<!-- captions serve much like titles, are usually capitalized except for words -->
<!-- such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to -->
<!-- and up, which are usually not capitalized unless they are the first or -->
<!-- last word of the caption. Table text will default to \footnotesize as -->
<!-- the IEEE normally uses this smaller font for tables. -->
<!-- The \label must come after \caption as always. -->

<!-- \begin{table}[!t] -->
<!-- % increase table row spacing, adjust to taste -->
<!-- \renewcommand{\arraystretch}{1.3} -->
<!-- if using array.sty, it might be a good idea to tweak the value of -->
<!-- \extrarowheight as needed to properly center the text within the cells -->
<!-- \caption{An Example of a Table} -->
<!-- \label{table_example} -->
<!-- \centering -->
<!-- % Some packages, such as MDW tools, offer better commands for making tables -->
<!-- % than the plain LaTeX2e tabular which is used here. -->
<!-- \begin{tabular}{|c||c|} -->
<!-- \hline -->
<!-- One & Two\\ -->
<!-- \hline -->
<!-- Three & Four\\ -->
<!-- \hline -->
<!-- \end{tabular} -->
<!-- \end{table} -->


<!-- Note that the IEEE does not put floats in the very first column -->
<!-- - or typically anywhere on the first page for that matter. Also, -->
<!-- in-text middle ("here") positioning is typically not used, but it -->
<!-- is allowed and encouraged for Computer Society conferences (but -->
<!-- not Computer Society journals). Most IEEE journals/conferences use -->
<!-- top floats exclusively.  -->
<!-- Note that, LaTeX2e, unlike IEEE journals/conferences, places -->
<!-- footnotes above bottom floats. This can be corrected via the -->
<!-- \fnbelowfloat command of the stfloats package. -->


# Conclusion

<!-- Here are two sample references: @Feynman1963118 [@Dirac1953888]. -->

<!--\newpage-->
<!--References {#references .numbered}-->
